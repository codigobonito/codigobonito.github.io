# Capítulo 4 -  Working with Remote Machines

## Participantes
- Diana Müller
- Ester
- Gabriel Fonseca
- Gabriela Flores
- Cristal
- Isaac
- Tiago Lubiana
- Vini Salazar


## Anúncios
- Congresso da RSG Argentina e Chile: https://womenbioinfodatascla.github.io/WomenBioinfoDataScLA/# 
- Mais congresso de mulheres em STEM https://www.bio.ifi.lmu.de/mitarbeiter/caroline-friedel/women-in-bioinformatics/
   

## Apresentações

- Diana: PPGBM - URFGS, genômica e epigenética, defende doutorado sexta
- Gabriel Fonseca: Química pela  USP, lab da Ester, RNAseq, iniciando em bioinfo



## Comentários

#### Discussão do cap. 4 -  Working with Remote Machines


- A pandemia motivou o uso do servidor pra alguns. 
Antes quem usava no laboratório usava de uma forma mais simples.
No hospital, toda hora tem alguém atacando o servidor, aí dificulta. 

- Na hora de aprender, já aconteceu de ter:
  - Tutorial desatualizado
  - Tutorial que não era adequado para ssh - apenas acesso remoto via google 

- Ter que aprender tudo por fora. Tomar até bronca por usar de outro jeito. 

- Um membro trabalhou em uma empresa e lá ele aprendeu a usar os servidores remotos.
Quando entrou no lab já manjava mais. 

- Aparentemente, os membros não possuem treinamento formal para acesso remoto.
- Pessoas com dificuldade de utilizar servidor.
  - Muita gente tem dificuldade com conexão, não sabe usar nohup ou tmux, e aí dá problemas. 
  - Até rola tentar fazer uns eventos para explicar como usar, mas não dá muito certo. 
  - Terminalfobia e falta de experiencia com Linux mesmo. 
  - Problemas com submissão de jobs são comuns também, por que não é tão simples.
Há muito compartilhamento de conhecimento por "via oral" nos laboratórios, com o esquema é na linha de "ooo Diogo, como é que faz tal coisa?" E vai aprendendo. 
Quando as pessoas se formam ou mudam de laboratório, às vezes o conhecimento é perdido.
Seria interessante documentar essas boas práticas pra colegas no futuro.

- As práticas mudam muito quando se troca a escala do laboratório. 

  - Labs maiores tem maior burocracia. Menores todo mundo tem sudo, maiores poderes mas maiores perigos; 
  - Tutorial muito avançado, não tinha coisas básicas;
  - Sem organização - quem tá mandando o que, quanto de processamento ta usando e etc;
  - Acaba privilegiando quem manda os jobs diretamente;
  - Hierarquia de jobs - mais organizado
  - Gerenciamento do servidor
    - Técnico que cuida do servidor - prós e contras;
    - Frequentemente fica na carga de um aluno pra gerenciar isso, que nem sempre tem o treinamento para isso. 
    - Acumulo de função estraga muito.
    - Quando tem, é comum estar longe de um usuário. 

- A divisão de cada nodo, é um pouco diferente para cada sistema. É importante saber como as coisas funcionam.


- Criar um apelido pro host é legal. 

- Usar autenticação com chaves SSH é bastante útil e pouca tempo. 

- TMUX é interessante, mas não entendi direito como usar. 

- TMUX é um gerenciador, que dá para criar sessões e tal. O SSH é o protocolo de identificação. Para modificar um repositório do GitHub pelo servidor, por exemplo, dá pra mandar para o GitHub via SSH. 

- O TMUX evita que quando a tela é fechada, o programa seja cortado. O TMUX faz muita coisa além do nohup, para coisas complexas o TMUX facilita muito. 
- Tinha gente do grupo que usava TMUX, mas não conheciam o nohup. 

- O pessoal configura o TMUX pra abrir bonito as coisas


- Para as chaves SSH, é bom ter um par para cada coisa diferente. A pública fica no servidor, a privada fica no computador. Se alguém tem acesso físico ao computador, compromete a segurança do remoto, mas isso já é comprometido independente da chave. 

- Faltou um pouco sobre enviar e receber arquivos do servidor. Uma opção é usar o 'rsync', que é muito útil. 

- Para texto plano e curto (como um script), ctrl-c, ctrl-v já funciona bastante. 

- Dá para usar o `scp`, que é a versão "segura" do `cp` do Linux, que transfere arquivos do PC pessoal pro servidor. O `rsync` sincroniza aos poucos e dá uns poderes extras, e ajuda a transportar arquivos grandes porque faz a sincronização aos poucos, assim não se perde o que foi feito caso a conexão seja perdida. 

- Tem gente que usa o filezilla, que é uma interface gráfica que ajuda a mandar coisas. Para quem adentra o mundo do SSH rápido, é uma opção tranquila. 
 
- Uma coisa legal também é rodar o Jupyter remotamente, e renderizar na máquina local. Para fazer análise exploratória é show. 

- O vscode dá para fazer uma integração com o servidor.
- nohup salva vidas 

## Semana seguinte

- Vini vai mostrar como usar o Jupyter no servidor no início;
- Ler o capítulo 5: **Git for Scientists**
