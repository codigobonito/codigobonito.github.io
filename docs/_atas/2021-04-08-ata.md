# Capítulo 7 - Unix Data Tools

## Participantes

Pedro Medeiros
Tiago Lubiana
João Vitor
Ícaro
Isaac
Ester
Diana

## Anúncios

- Vueconf (https://vueconf.us/) vai rolar, dia 14/04, as incrições são até dia 13/04, de graça.

- Projeto de mapear as pessoas de bioinfo usando wikidata. O tutorial  é: https://tiagolubiana.medium.com/adicionando-cientistas-ao-sistema-wikidata-scholia-6b73ae5e59e2

- Limitar as discussões off-topic no grupo?
    - Criar um canal para anúncios, enquanto o grupo fica pra discussões

## Apresentações
## Comentários

**Comentários gerais sobre o capítulo**

- A ideia geral do capítulo é que tudo no UNIX é baseado em _streams_ e _pipes_, e esse encadeamento é bem legal. 

Um programa em Python teria que ser pensado para isso, lendo por stream. O read_line faz isso, por exemplo. 

O módulo csv do python trabalha com stream. 

Os geradores/iteradores no Python (yield e tal) tem coisas de stream.

O UNIX fez isso por que a memória de HD é maior que a de processamento/execução (RAM), pra fazer a execução em pedaços. Aí economiza, por que processa em pedaços ("chunks"). 

Eu tenho a impressão que a gente não usa tanto streams em bioinformática. 

Os arquivos .h5ad de single-cell transcriptomics tem uns truques que acabam usando algo como um stream. E realmente acaba economizando muita memória, é uma forma de lidar com _big data_, que excede o RAM dos computadores. 

Acho que é até uma boa definição de big data: o que não dá para subir no RAM de um laptop médio. 

O bash é muitas vezes mais rápido. 
As linguagens geralmente usam uma só _thread_, um só _núcleo_ do computador, e o bash lida bem. 

Achei uma função do Python que servia para rodar coisas do bash, podendo salvar o output do bash numa variável. 

Essas coisas do UNIX são bem compatíveis com Linux e MacOS, o que é uma coisa valiosa. Filogeneticamente eles tão bem perto. Mas o windows tá melhorando, o que é legal.

O subsistema Linux para Windows é bacana pra quem não quer fazer a transição pra Linux.



As vezes vem alguém muito fera para dar um curso e fica ensinando básico de UNIX/Linux.
É bom ser preparado antes, ou dado como um pré-requisito pra um curso ou algo assim. (curso da UFRGS para introdução e avançado em Linux https://cesup.ufrgs.br/imagens-1/cursos)

_sed_ e _awk_ são muito bacanas, o pessoal as vezes faz coisas mirabolantes com grep que sed e awk são simples.

Um comandinho muito útil é o _diff_ também. Legal pra compartilhar diferenças que é o "diff" e o "patch".


Uma coisa um pouco mais diferente são os _named pipelines_. (mas ninguém sabia muito)

O _join_ que ele menciona no capítulo, do terminal, é bem simples e muito rápido. Carregar na memória no R e tal para fazer merges é _muito_ custoso e muito comum, fazer via joins é mais rápido e bem mais barato. Vale conhecer. 

Outra coisa de bash/unix que é muito legal é o & pra jogar o processo pra background. Nohup é um ótimo acompanhamento.


Regra do "dedão" de quando usar cada coisa (Ester):

    - Coisa de estatística e fazer gráfico: R
    - Processamento e conversar com API: Python
    - Coisas muito básicas (tipo desse capítulo): Bash
    
### Próxima semana - Discussão do cap. 8 - Introdução ao R

## Off:

Função em Python (3.x) para usar o bash. Permite salvar o output do bash em uma variável.

```python
#!/usr/bin/python
# -*- coding: utf-8 -*-
from subprocess import PIPE, Popen

def cmdline(command):
    process = Popen(
        args=command,
        stdout=PIPE,
        shell=True
    )
    
    return process.communicate()[0].decode(encoding='UTF-8')

lx = '-X'
my_files_with_extension = cmdline(f"ls {lx}")
print(my_files_with_extension)

```

É muito bom estudar testes unitários e debugging. Mais bioinformatas deveriam aprender.
